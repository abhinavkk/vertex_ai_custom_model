{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "00JD6eeoCbhQ",
      "metadata": {
        "id": "00JD6eeoCbhQ"
      },
      "source": [
        "## Vertex AI: Local Model Custom Container Deployment"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "EkXL-CIhCiFS",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "executionInfo": {
          "elapsed": 7833,
          "status": "ok",
          "timestamp": 1735717851916,
          "user": {
            "displayName": "",
            "userId": ""
          },
          "user_tz": -330
        },
        "id": "EkXL-CIhCiFS",
        "outputId": "3ce2ab16-6072-4d6c-8e17-33c7215e4376"
      },
      "outputs": [],
      "source": [
        "# Initialize the Vertex AI client with the desired region\n",
        "aiplatform.init(project=\"<Project-Id>\", location=\"<Region>\")\n",
        "\n",
        "# Create the endpoint\n",
        "endpoint = aiplatform.Endpoint.create(\n",
        "    display_name=\"service_request_classification_standard\",\n",
        "    # dedicated_endpoint_enabled=True  # Correct parameter for enabling dedicated resources\n",
        ")\n",
        "\n",
        "print(f\"Endpoint created: {endpoint.resource_name}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6rls52_eCiFT",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "executionInfo": {
          "elapsed": 4944,
          "status": "ok",
          "timestamp": 1735717867191,
          "user": {
            "displayName": "",
            "userId": ""
          },
          "user_tz": -330
        },
        "id": "6rls52_eCiFT",
        "outputId": "13fdae52-5007-460c-c420-8c0eccb088b9"
      },
      "outputs": [],
      "source": [
        "!gcloud ai endpoints list \\\n",
        "  --region=<Region> \\\n",
        "  --filter=display_name='service_request_classification_standard'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "OQAF8uY4CiFT",
      "metadata": {
        "id": "OQAF8uY4CiFT"
      },
      "outputs": [],
      "source": [
        "# Load the endpoint\n",
        "endpoint_id = \"<Endpoint-Id>\"  # Replace with your endpoint ID\n",
        "project_id = '<GCP Project Name>'\n",
        "region = '<Region>'\n",
        "endpoint = aiplatform.Endpoint(endpoint_name=f\"projects/{project_id}/locations/{region}/endpoints/{endpoint_id}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "FJOa7Ld7CiFT",
      "metadata": {
        "id": "FJOa7Ld7CiFT"
      },
      "outputs": [],
      "source": [
        "def deploy_model_with_dedicated_resources_sample(\n",
        "    project,\n",
        "    location,\n",
        "    model_name: str,\n",
        "    machine_type: str,\n",
        "    endpoint: Optional[aiplatform.Endpoint] = None,\n",
        "    deployed_model_display_name: Optional[str] = None,\n",
        "    traffic_percentage: Optional[int] = 0,\n",
        "    traffic_split: Optional[Dict[str, int]] = None,\n",
        "    min_replica_count: int = 1,\n",
        "    max_replica_count: int = 1,\n",
        "    accelerator_type: Optional[str] = None,\n",
        "    accelerator_count: Optional[int] = None,\n",
        "    # explanation_metadata: Optional[explain.ExplanationMetadata] = None,\n",
        "    # explanation_parameters: Optional[explain.ExplanationParameters] = None,\n",
        "    # metadata: Optional[Sequence[Tuple[str, str]]] = (),\n",
        "    sync: bool = True,\n",
        "):\n",
        "    \"\"\"\n",
        "    model_name: A fully-qualified model resource name or model ID.\n",
        "          Example: \"projects/123/locations/us-central1/models/456\" or\n",
        "          \"456\" when project and location are initialized or passed.\n",
        "    \"\"\"\n",
        "\n",
        "    aiplatform.init(project=project, location=location)\n",
        "\n",
        "    model = aiplatform.Model(model_name=model_name)\n",
        "\n",
        "    # The explanation_metadata and explanation_parameters should only be\n",
        "    # provided for a custom trained model and not an AutoML model.\n",
        "    model.deploy(\n",
        "        endpoint=endpoint,\n",
        "        deployed_model_display_name=deployed_model_display_name,\n",
        "        traffic_percentage=traffic_percentage,\n",
        "        traffic_split=traffic_split,\n",
        "        machine_type=machine_type,\n",
        "        min_replica_count=min_replica_count,\n",
        "        max_replica_count=max_replica_count,\n",
        "        accelerator_type=accelerator_type,\n",
        "        accelerator_count=accelerator_count,\n",
        "        # explanation_metadata=explanation_metadata,\n",
        "        # explanation_parameters=explanation_parameters,\n",
        "        # metadata=metadata,\n",
        "        sync=sync,\n",
        "    )\n",
        "\n",
        "    model.wait()\n",
        "\n",
        "    print(model.display_name)\n",
        "    print(model.resource_name)\n",
        "    return model\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d3PG9xejCiFT",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "executionInfo": {
          "elapsed": 1029934,
          "status": "ok",
          "timestamp": 1735718952877,
          "user": {
            "displayName": "",
            "userId": ""
          },
          "user_tz": -330
        },
        "id": "d3PG9xejCiFT",
        "outputId": "e46f6d1e-8796-419c-8b05-40b657bc631e"
      },
      "outputs": [],
      "source": [
        "output = deploy_model_with_dedicated_resources_sample(project='<GCP Project Name>', location='<Region>', model_name= '<Model-Name>', machine_type= 'n2-standard-80', endpoint=endpoint)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "w4jhgDbu1eTc",
      "metadata": {
        "id": "w4jhgDbu1eTc"
      },
      "source": [
        "## Hugging Face Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "jWSxoHfh1nX4",
      "metadata": {
        "executionInfo": {
          "elapsed": 12150,
          "status": "ok",
          "timestamp": 1735711488824,
          "user": {
            "displayName": "",
            "userId": ""
          },
          "user_tz": -330
        },
        "id": "jWSxoHfh1nX4"
      },
      "outputs": [],
      "source": [
        "from google.cloud import aiplatform\n",
        "from typing import Optional\n",
        "from typing import Dict"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1vlUR6r5QK4b",
      "metadata": {
        "id": "1vlUR6r5QK4b"
      },
      "outputs": [],
      "source": [
        "def create_endpoint_sample(\n",
        "    project: str,\n",
        "    display_name: str,\n",
        "    location: str,\n",
        "):\n",
        "    aiplatform.init(project=project, location=location)\n",
        "\n",
        "    endpoint = aiplatform.Endpoint.create(\n",
        "        display_name=display_name,\n",
        "        project=project,\n",
        "        location=location,\n",
        "    )\n",
        "\n",
        "    print(endpoint.display_name)\n",
        "    print(endpoint.resource_name)\n",
        "    return endpoint\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "GyIsWYr0QL67",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "executionInfo": {
          "elapsed": 8756,
          "status": "ok",
          "timestamp": 1734952964990,
          "user": {
            "displayName": "",
            "userId": ""
          },
          "user_tz": -330
        },
        "id": "GyIsWYr0QL67",
        "outputId": "1c58fdb1-0571-4832-8a3a-99f43dfa609c"
      },
      "outputs": [],
      "source": [
        "endpoint = aiplatform.Endpoint.create(\n",
        "  display_name=\"service_request_classification\",\n",
        "  dedicated_endpoint_enabled=True,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "sGxbDnAOOryn",
      "metadata": {
        "executionInfo": {
          "elapsed": 14,
          "status": "ok",
          "timestamp": 1735711488825,
          "user": {
            "displayName": "",
            "userId": ""
          },
          "user_tz": -330
        },
        "id": "sGxbDnAOOryn"
      },
      "outputs": [],
      "source": [
        "# Load the endpoint\n",
        "endpoint_id = \"<Endpoint-Id>\"  # Replace with your endpoint ID\n",
        "project_id = '<GCP Project Name>'\n",
        "region = '<Region>'\n",
        "endpoint = aiplatform.Endpoint(endpoint_name=f\"projects/{project_id}/locations/{region}/endpoints/{endpoint_id}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "96i1CQCfQSg8",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "executionInfo": {
          "elapsed": 3058,
          "status": "ok",
          "timestamp": 1734953057872,
          "user": {
            "displayName": "",
            "userId": ""
          },
          "user_tz": -330
        },
        "id": "96i1CQCfQSg8",
        "outputId": "5c8fe104-31ac-4453-a2f1-67a5d6be3d67"
      },
      "outputs": [],
      "source": [
        "!gcloud ai endpoints list \\\n",
        "  --region=<Region> \\\n",
        "  --filter=display_name='service_request_classification'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "BuNMsY_ZQlxE",
      "metadata": {
        "executionInfo": {
          "elapsed": 6,
          "status": "ok",
          "timestamp": 1735711500401,
          "user": {
            "displayName": "",
            "userId": ""
          },
          "user_tz": -330
        },
        "id": "BuNMsY_ZQlxE"
      },
      "outputs": [],
      "source": [
        "def deploy_model_with_dedicated_resources_sample(\n",
        "    project,\n",
        "    location,\n",
        "    model_name: str,\n",
        "    machine_type: str,\n",
        "    endpoint: Optional[aiplatform.Endpoint] = None,\n",
        "    deployed_model_display_name: Optional[str] = None,\n",
        "    traffic_percentage: Optional[int] = 0,\n",
        "    traffic_split: Optional[Dict[str, int]] = None,\n",
        "    min_replica_count: int = 1,\n",
        "    max_replica_count: int = 1,\n",
        "    accelerator_type: Optional[str] = None,\n",
        "    accelerator_count: Optional[int] = None,\n",
        "    # explanation_metadata: Optional[explain.ExplanationMetadata] = None,\n",
        "    # explanation_parameters: Optional[explain.ExplanationParameters] = None,\n",
        "    # metadata: Optional[Sequence[Tuple[str, str]]] = (),\n",
        "    sync: bool = True,\n",
        "):\n",
        "    \"\"\"\n",
        "    model_name: A fully-qualified model resource name or model ID.\n",
        "          Example: \"projects/123/locations/us-central1/models/456\" or\n",
        "          \"456\" when project and location are initialized or passed.\n",
        "    \"\"\"\n",
        "\n",
        "    aiplatform.init(project=project, location=location)\n",
        "\n",
        "    model = aiplatform.Model(model_name=model_name)\n",
        "\n",
        "    # The explanation_metadata and explanation_parameters should only be\n",
        "    # provided for a custom trained model and not an AutoML model.\n",
        "    model.deploy(\n",
        "        endpoint=endpoint,\n",
        "        deployed_model_display_name=deployed_model_display_name,\n",
        "        traffic_percentage=traffic_percentage,\n",
        "        traffic_split=traffic_split,\n",
        "        machine_type=machine_type,\n",
        "        min_replica_count=min_replica_count,\n",
        "        max_replica_count=max_replica_count,\n",
        "        accelerator_type=accelerator_type,\n",
        "        accelerator_count=accelerator_count,\n",
        "        # explanation_metadata=explanation_metadata,\n",
        "        # explanation_parameters=explanation_parameters,\n",
        "        # metadata=metadata,\n",
        "        sync=sync,\n",
        "    )\n",
        "\n",
        "    model.wait()\n",
        "\n",
        "    print(model.display_name)\n",
        "    print(model.resource_name)\n",
        "    return model\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "L8Vo_kg5Qy6a",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "executionInfo": {
          "elapsed": 148441,
          "status": "ok",
          "timestamp": 1735712767862,
          "user": {
            "displayName": "",
            "userId": ""
          },
          "user_tz": -330
        },
        "id": "L8Vo_kg5Qy6a",
        "outputId": "d0351771-6701-45d0-c090-0bfd3d7dfc46"
      },
      "outputs": [],
      "source": [
        "output = deploy_model_with_dedicated_resources_sample(project='<GCP Project Name>', location='<Region>', model_name= '<Model-Name>', machine_type= 'n2-standard-80', endpoint=endpoint)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "DrURp1SCApK2",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "executionInfo": {
          "elapsed": 72225,
          "status": "ok",
          "timestamp": 1735133480386,
          "user": {
            "displayName": "",
            "userId": ""
          },
          "user_tz": -330
        },
        "id": "DrURp1SCApK2",
        "outputId": "960bd5ce-c7d2-49a1-feba-dc51050112ec"
      },
      "outputs": [],
      "source": [
        "!gcloud auth application-default login\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cq1qj4c6wbOW",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "executionInfo": {
          "elapsed": 15,
          "status": "ok",
          "timestamp": 1735712882180,
          "user": {
            "displayName": "",
            "userId": ""
          },
          "user_tz": -330
        },
        "id": "cq1qj4c6wbOW",
        "outputId": "999c871f-bc31-41e3-bd0b-be03ccbc172b"
      },
      "outputs": [],
      "source": [
        "!curl -X POST \\\n",
        "-H \"Content-Type: application/json\" \\\n",
        "-d '{\"instances\": [{\"text\": \"I love this!\"}, {\"text\": \"I hate this!\"}]}' \\\n",
        "https://<Endpoint-Id>.<Region>-<Project-Id>.prediction.vertexai.goog/predict\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "hXMV-1LkwBFf",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "executionInfo": {
          "elapsed": 19,
          "status": "ok",
          "timestamp": 1735196179444,
          "user": {
            "displayName": "",
            "userId": ""
          },
          "user_tz": -330
        },
        "id": "hXMV-1LkwBFf",
        "outputId": "f867070f-69d6-4cf6-fdf9-70eec0014f61"
      },
      "outputs": [],
      "source": [
        "!curl -X POST \\\n",
        "-H \"Content-Type: application/json\" \\\n",
        "-d '{\"instances\": [\"I love this!\", \"I hate this!\"]}' \\\n",
        "https://<Endpoint-Id>.<Region>-<Project-Id>.prediction.vertexai.goog/predict\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "10en5bZpkO9O",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "executionInfo": {
          "elapsed": 3673,
          "status": "ok",
          "timestamp": 1735713259062,
          "user": {
            "displayName": "",
            "userId": ""
          },
          "user_tz": -330
        },
        "id": "10en5bZpkO9O",
        "outputId": "8c0a71af-7353-4622-9587-dfba8f196cfc"
      },
      "outputs": [],
      "source": [
        "! curl \\\n",
        "-H \"Authorization: Bearer $(gcloud auth print-access-token)\" \\\n",
        "-H \"Content-Type: application/json\" \\\n",
        "-d '{\"instances\": [\"I love this!\", \"I hate this!\"]}' \\\n",
        "https://<Region>-aiplatform.googleapis.com/v1/projects/<Project-Id>/locations/<Region>/endpoints/<Endpoint-Id>:predict"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "P6QuIvpDBPJ3",
      "metadata": {
        "id": "P6QuIvpDBPJ3"
      },
      "outputs": [],
      "source": [
        "curl \\ -X POST \\ -H \"Authorization: Bearer $(gcloud auth print-access-token)\" \\ -H \"Content-Type: application/json\" \\ \"https://<Endpoint-Id>.<Region>-<Project-Id>.prediction.vertexai.goog/v1/projects/${PROJECT_ID}/locations/<Region>/endpoints/${ENDPOINT_ID}:predict\" \\ -d \"@${INPUT_DATA_FILE}\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "JtYwiSihyW8g",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "executionInfo": {
          "elapsed": 2584,
          "status": "ok",
          "timestamp": 1735133024143,
          "user": {
            "displayName": "",
            "userId": ""
          },
          "user_tz": -330
        },
        "id": "JtYwiSihyW8g",
        "outputId": "73962355-efa1-46b4-f184-2ccbfa4afe13"
      },
      "outputs": [],
      "source": [
        "!gcloud ai endpoints list --project='<GCP Project Name>' --region=<Region>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "XwNCKE2dzunY",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "executionInfo": {
          "elapsed": 33,
          "status": "ok",
          "timestamp": 1735130037003,
          "user": {
            "displayName": "",
            "userId": ""
          },
          "user_tz": -330
        },
        "id": "XwNCKE2dzunY",
        "outputId": "6e2dd7f3-93a3-4ee1-d002-7e1426c2dcad"
      },
      "outputs": [],
      "source": [
        "!gcloud ai endpoints describe <Endpoint-Id> --project='<GCP Project Name>' --region=<Region>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "OGOFYE6Qyvc7",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "executionInfo": {
          "elapsed": 1242,
          "status": "ok",
          "timestamp": 1735133338653,
          "user": {
            "displayName": "",
            "userId": ""
          },
          "user_tz": -330
        },
        "id": "OGOFYE6Qyvc7",
        "outputId": "8338a4dd-f96b-410d-fb4c-34da8b5d8a2b"
      },
      "outputs": [],
      "source": [
        "import json\n",
        "import requests\n",
        "from google.auth import default\n",
        "from google.auth.transport.requests import Request\n",
        "\n",
        "# Replace with your actual values\n",
        "project_id = \"<Project-Id>\"\n",
        "endpoint_id = \"<Endpoint-Id>\"\n",
        "location = \"<Region>\"\n",
        "url = \"https://<Endpoint-Id>.<Region>-<Project-Id>.prediction.vertexai.goog/v1/predict\"\n",
        "\n",
        "# Define the instances and parameters for your model input\n",
        "instances = [{\"text\": \"I want to take a loan\"}]\n",
        "parameters = {\n",
        "    \"temperature\": 0.7,\n",
        "    \"maxOutputTokens\": 5000,\n",
        "    \"topP\": 0.8,\n",
        "    \"topK\": 40,\n",
        "}\n",
        "\n",
        "# Prepare the payload\n",
        "payload = {\n",
        "    \"instances\": instances\n",
        "    # Uncomment the line below if your model supports parameters\n",
        "    # \"parameters\": parameters,\n",
        "}\n",
        "\n",
        "# Get the authentication token\n",
        "credentials, _ = default()\n",
        "credentials.refresh(Request())\n",
        "token = credentials.token\n",
        "\n",
        "# Set up the request headers\n",
        "headers = {\n",
        "    \"Authorization\": f\"Bearer {token}\",\n",
        "    \"Content-Type\": \"application/json\",\n",
        "}\n",
        "\n",
        "# Send the POST request\n",
        "response = requests.post(url, headers=headers, json=payload)\n",
        "\n",
        "# Check the response\n",
        "if response.status_code == 200:\n",
        "    print(\"Response:\", response.json())\n",
        "else:\n",
        "    print(f\"Error: {response.status_code}, {response.text}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ZbtlXYA32oaM",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "executionInfo": {
          "elapsed": 3617,
          "status": "ok",
          "timestamp": 1735712924865,
          "user": {
            "displayName": "",
            "userId": ""
          },
          "user_tz": -330
        },
        "id": "ZbtlXYA32oaM",
        "outputId": "74baecf1-0f28-4fcc-d539-c46238acf2a2"
      },
      "outputs": [],
      "source": [
        "!curl -X GET \\\n",
        "https://<Endpoint-Id>.<Region>-<Project-Id>.prediction.vertexai.goog/\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "RGuazxHyThdY",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "executionInfo": {
          "elapsed": 2434,
          "status": "ok",
          "timestamp": 1734954096917,
          "user": {
            "displayName": "",
            "userId": ""
          },
          "user_tz": -330
        },
        "id": "RGuazxHyThdY",
        "outputId": "a7ac04a5-f149-48b7-853c-b114ae4bd0fe"
      },
      "outputs": [],
      "source": [
        "!gcloud compute machine-types list --zones='<Region>-a'\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ij4GSr9S2DJV",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "executionInfo": {
          "elapsed": 7833,
          "status": "ok",
          "timestamp": 1735717851916,
          "user": {
            "displayName": "",
            "userId": ""
          },
          "user_tz": -330
        },
        "id": "ij4GSr9S2DJV",
        "outputId": "3ce2ab16-6072-4d6c-8e17-33c7215e4376"
      },
      "outputs": [],
      "source": [
        "# Initialize the Vertex AI client with the desired region\n",
        "aiplatform.init(project=\"<Project-Id>\", location=\"<Region>\")\n",
        "\n",
        "# Create the endpoint\n",
        "endpoint = aiplatform.Endpoint.create(\n",
        "    display_name=\"service_request_classification_standard\",\n",
        "    # dedicated_endpoint_enabled=True  # Correct parameter for enabling dedicated resources\n",
        ")\n",
        "\n",
        "print(f\"Endpoint created: {endpoint.resource_name}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ubNwBBgj2DJX",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "executionInfo": {
          "elapsed": 4944,
          "status": "ok",
          "timestamp": 1735717867191,
          "user": {
            "displayName": "",
            "userId": ""
          },
          "user_tz": -330
        },
        "id": "ubNwBBgj2DJX",
        "outputId": "13fdae52-5007-460c-c420-8c0eccb088b9"
      },
      "outputs": [],
      "source": [
        "!gcloud ai endpoints list \\\n",
        "  --region=<Region> \\\n",
        "  --filter=display_name='service_request_classification_standard'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "RgwvviFR2DJX",
      "metadata": {
        "executionInfo": {
          "elapsed": 4068,
          "status": "ok",
          "timestamp": 1735717881039,
          "user": {
            "displayName": "",
            "userId": ""
          },
          "user_tz": -330
        },
        "id": "RgwvviFR2DJX"
      },
      "outputs": [],
      "source": [
        "# Load the endpoint\n",
        "endpoint_id = \"<Endpoint-Id>\"  # Replace with your endpoint ID\n",
        "project_id = '<GCP Project Name>'\n",
        "region = '<Region>'\n",
        "endpoint = aiplatform.Endpoint(endpoint_name=f\"projects/{project_id}/locations/{region}/endpoints/{endpoint_id}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "FJ_aR34u2DJY",
      "metadata": {
        "executionInfo": {
          "elapsed": 3,
          "status": "ok",
          "timestamp": 1735717885123,
          "user": {
            "displayName": "",
            "userId": ""
          },
          "user_tz": -330
        },
        "id": "FJ_aR34u2DJY"
      },
      "outputs": [],
      "source": [
        "def deploy_model_with_dedicated_resources_sample(\n",
        "    project,\n",
        "    location,\n",
        "    model_name: str,\n",
        "    machine_type: str,\n",
        "    endpoint: Optional[aiplatform.Endpoint] = None,\n",
        "    deployed_model_display_name: Optional[str] = None,\n",
        "    traffic_percentage: Optional[int] = 0,\n",
        "    traffic_split: Optional[Dict[str, int]] = None,\n",
        "    min_replica_count: int = 1,\n",
        "    max_replica_count: int = 1,\n",
        "    accelerator_type: Optional[str] = None,\n",
        "    accelerator_count: Optional[int] = None,\n",
        "    # explanation_metadata: Optional[explain.ExplanationMetadata] = None,\n",
        "    # explanation_parameters: Optional[explain.ExplanationParameters] = None,\n",
        "    # metadata: Optional[Sequence[Tuple[str, str]]] = (),\n",
        "    sync: bool = True,\n",
        "):\n",
        "    \"\"\"\n",
        "    model_name: A fully-qualified model resource name or model ID.\n",
        "          Example: \"projects/123/locations/us-central1/models/456\" or\n",
        "          \"456\" when project and location are initialized or passed.\n",
        "    \"\"\"\n",
        "\n",
        "    aiplatform.init(project=project, location=location)\n",
        "\n",
        "    model = aiplatform.Model(model_name=model_name)\n",
        "\n",
        "    # The explanation_metadata and explanation_parameters should only be\n",
        "    # provided for a custom trained model and not an AutoML model.\n",
        "    model.deploy(\n",
        "        endpoint=endpoint,\n",
        "        deployed_model_display_name=deployed_model_display_name,\n",
        "        traffic_percentage=traffic_percentage,\n",
        "        traffic_split=traffic_split,\n",
        "        machine_type=machine_type,\n",
        "        min_replica_count=min_replica_count,\n",
        "        max_replica_count=max_replica_count,\n",
        "        accelerator_type=accelerator_type,\n",
        "        accelerator_count=accelerator_count,\n",
        "        # explanation_metadata=explanation_metadata,\n",
        "        # explanation_parameters=explanation_parameters,\n",
        "        # metadata=metadata,\n",
        "        sync=sync,\n",
        "    )\n",
        "\n",
        "    model.wait()\n",
        "\n",
        "    print(model.display_name)\n",
        "    print(model.resource_name)\n",
        "    return model\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "BkZyg-2D2DJY",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "executionInfo": {
          "elapsed": 1029934,
          "status": "ok",
          "timestamp": 1735718952877,
          "user": {
            "displayName": "",
            "userId": ""
          },
          "user_tz": -330
        },
        "id": "BkZyg-2D2DJY",
        "outputId": "e46f6d1e-8796-419c-8b05-40b657bc631e"
      },
      "outputs": [],
      "source": [
        "output = deploy_model_with_dedicated_resources_sample(project='<GCP Project Name>', location='<Region>', model_name= '<Model-Name>', machine_type= 'n2-standard-80', endpoint=endpoint)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "wRY-Dz9vlaw2",
      "metadata": {
        "id": "wRY-Dz9vlaw2"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "WKNWuawJlbn_",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "executionInfo": {
          "elapsed": 3507,
          "status": "ok",
          "timestamp": 1735713644540,
          "user": {
            "displayName": "",
            "userId": ""
          },
          "user_tz": -330
        },
        "id": "WKNWuawJlbn_",
        "outputId": "4f499401-dc09-488c-8966-07e4e3f93c44"
      },
      "outputs": [],
      "source": [
        "# Initialize the Vertex AI client with the desired region\n",
        "aiplatform.init(project=\"<Project-Id>\", location=\"us-central1\")\n",
        "\n",
        "# Create the endpoint\n",
        "endpoint = aiplatform.Endpoint.create(\n",
        "    display_name=\"service_request_classification\",\n",
        "    dedicated_endpoint_enabled=True  # Correct parameter for enabling dedicated resources\n",
        ")\n",
        "\n",
        "print(f\"Endpoint created: {endpoint.resource_name}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "QlNnqyEsliVg",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "executionInfo": {
          "elapsed": 7258,
          "status": "ok",
          "timestamp": 1735713690570,
          "user": {
            "displayName": "",
            "userId": ""
          },
          "user_tz": -330
        },
        "id": "QlNnqyEsliVg",
        "outputId": "9d6d22f8-b2bd-48a5-b325-05ea15b2e6f1"
      },
      "outputs": [],
      "source": [
        "!gcloud ai endpoints list \\\n",
        "  --region=us-central1 \\\n",
        "  --filter=display_name='service_request_classification'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "Y8JdfoNmmLij",
      "metadata": {
        "executionInfo": {
          "elapsed": 1356,
          "status": "ok",
          "timestamp": 1735713726985,
          "user": {
            "displayName": "",
            "userId": ""
          },
          "user_tz": -330
        },
        "id": "Y8JdfoNmmLij"
      },
      "outputs": [],
      "source": [
        "# Load the endpoint\n",
        "endpoint_id = \"<Endpoint-Id>\"  # Replace with your endpoint ID\n",
        "project_id = '<GCP Project Name>'\n",
        "region = 'us-central1'\n",
        "endpoint = aiplatform.Endpoint(endpoint_name=f\"projects/{project_id}/locations/{region}/endpoints/{endpoint_id}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "eiKcYh3emxcm",
      "metadata": {
        "executionInfo": {
          "elapsed": 3864,
          "status": "ok",
          "timestamp": 1735713835212,
          "user": {
            "displayName": "",
            "userId": ""
          },
          "user_tz": -330
        },
        "id": "eiKcYh3emxcm"
      },
      "outputs": [],
      "source": [
        "def deploy_model_with_dedicated_resources_sample(\n",
        "    project,\n",
        "    location,\n",
        "    model_name: str,\n",
        "    machine_type: str,\n",
        "    endpoint: Optional[aiplatform.Endpoint] = None,\n",
        "    deployed_model_display_name: Optional[str] = None,\n",
        "    traffic_percentage: Optional[int] = 0,\n",
        "    traffic_split: Optional[Dict[str, int]] = None,\n",
        "    min_replica_count: int = 1,\n",
        "    max_replica_count: int = 1,\n",
        "    accelerator_type: Optional[str] = None,\n",
        "    accelerator_count: Optional[int] = None,\n",
        "    # explanation_metadata: Optional[explain.ExplanationMetadata] = None,\n",
        "    # explanation_parameters: Optional[explain.ExplanationParameters] = None,\n",
        "    # metadata: Optional[Sequence[Tuple[str, str]]] = (),\n",
        "    sync: bool = True,\n",
        "):\n",
        "    \"\"\"\n",
        "    model_name: A fully-qualified model resource name or model ID.\n",
        "          Example: \"projects/123/locations/us-central1/models/456\" or\n",
        "          \"456\" when project and location are initialized or passed.\n",
        "    \"\"\"\n",
        "\n",
        "    aiplatform.init(project=project, location=location)\n",
        "\n",
        "    model = aiplatform.Model(model_name=model_name)\n",
        "\n",
        "    # The explanation_metadata and explanation_parameters should only be\n",
        "    # provided for a custom trained model and not an AutoML model.\n",
        "    model.deploy(\n",
        "        endpoint=endpoint,\n",
        "        deployed_model_display_name=deployed_model_display_name,\n",
        "        traffic_percentage=traffic_percentage,\n",
        "        traffic_split=traffic_split,\n",
        "        machine_type=machine_type,\n",
        "        min_replica_count=min_replica_count,\n",
        "        max_replica_count=max_replica_count,\n",
        "        accelerator_type=accelerator_type,\n",
        "        accelerator_count=accelerator_count,\n",
        "        # explanation_metadata=explanation_metadata,\n",
        "        # explanation_parameters=explanation_parameters,\n",
        "        # metadata=metadata,\n",
        "        sync=sync,\n",
        "    )\n",
        "\n",
        "    model.wait()\n",
        "\n",
        "    print(model.display_name)\n",
        "    print(model.resource_name)\n",
        "    return model\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "_kYHZKMrmxco",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "executionInfo": {
          "elapsed": 544374,
          "status": "ok",
          "timestamp": 1735715218380,
          "user": {
            "displayName": "",
            "userId": ""
          },
          "user_tz": -330
        },
        "id": "_kYHZKMrmxco",
        "outputId": "f82362b7-75ca-47a1-c4d3-3bc463142a23"
      },
      "outputs": [],
      "source": [
        "output = deploy_model_with_dedicated_resources_sample(project='<GCP Project Name>', location='us-central1', model_name= '<Model-Name>', machine_type= 'n2-standard-80', endpoint=endpoint)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "yQYwh6Fbm4Sk",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "executionInfo": {
          "elapsed": 4442,
          "status": "ok",
          "timestamp": 1735716376417,
          "user": {
            "displayName": "",
            "userId": ""
          },
          "user_tz": -330
        },
        "id": "yQYwh6Fbm4Sk",
        "outputId": "d8674f34-adca-41ee-d65f-1a1343eb10d6"
      },
      "outputs": [],
      "source": [
        "!curl -X POST \\\n",
        "-H \"Content-Type: application/json\" \\\n",
        "-d '{\"instances\": [\"I love this!\", \"I hate this!\"]}' \\\n",
        "<Endpoint-Id>.us-central1-<Project-Id>.prediction.vertexai.goog/predict\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "PgwYhzydsHtQ",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "executionInfo": {
          "elapsed": 9,
          "status": "ok",
          "timestamp": 1735716343686,
          "user": {
            "displayName": "",
            "userId": ""
          },
          "user_tz": -330
        },
        "id": "PgwYhzydsHtQ",
        "outputId": "724ab065-1c6d-43e2-dab3-0aad1949504e"
      },
      "outputs": [],
      "source": [
        "!curl -X GET \\\n",
        "<Endpoint-Id>.us-central1-<Project-Id>.prediction.vertexai.goog/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5kzrsPLmsZls",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "executionInfo": {
          "elapsed": 2832,
          "status": "error",
          "timestamp": 1735716589808,
          "user": {
            "displayName": "",
            "userId": ""
          },
          "user_tz": -330
        },
        "id": "5kzrsPLmsZls",
        "outputId": "eef2a281-50a2-49aa-c3c8-461bf357f30b"
      },
      "outputs": [],
      "source": [
        "result = endpoint.predict(instances=[\"I love this!\", \"I hate this!\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0pCHgP07xUBa",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "executionInfo": {
          "elapsed": 5279,
          "status": "ok",
          "timestamp": 1735716721929,
          "user": {
            "displayName": "",
            "userId": ""
          },
          "user_tz": -330
        },
        "id": "0pCHgP07xUBa",
        "outputId": "c7418dc7-f14d-4e5a-c106-77c5792ec824"
      },
      "outputs": [],
      "source": [
        "# Initialize the Vertex AI client with the desired region\n",
        "aiplatform.init(project=\"<Project-Id>\", location=\"us-central1\")\n",
        "\n",
        "# Create the endpoint\n",
        "endpoint = aiplatform.Endpoint.create(\n",
        "    display_name=\"service_request_classification_standard\",\n",
        "    # dedicated_endpoint_enabled=True  # Correct parameter for enabling dedicated resources\n",
        ")\n",
        "\n",
        "print(f\"Endpoint created: {endpoint.resource_name}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "hbdPZwGOxzmG",
      "metadata": {
        "id": "hbdPZwGOxzmG"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "xTccdQu4yckC",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "executionInfo": {
          "elapsed": 5155,
          "status": "ok",
          "timestamp": 1735716903079,
          "user": {
            "displayName": "",
            "userId": ""
          },
          "user_tz": -330
        },
        "id": "xTccdQu4yckC",
        "outputId": "3e7f9ccf-1e60-4d17-ba46-a5b5080680b8"
      },
      "outputs": [],
      "source": [
        "!gcloud ai endpoints list \\\n",
        "  --region=us-central1 \\\n",
        "  --filter=display_name='service_request_classification'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "Peb4vOAUyckE",
      "metadata": {
        "executionInfo": {
          "elapsed": 5,
          "status": "ok",
          "timestamp": 1735716932270,
          "user": {
            "displayName": "",
            "userId": ""
          },
          "user_tz": -330
        },
        "id": "Peb4vOAUyckE"
      },
      "outputs": [],
      "source": [
        "# Load the endpoint\n",
        "endpoint_id = \"<Endpoint-Id>\"  # Replace with your endpoint ID\n",
        "project_id = '<GCP Project Name>'\n",
        "region = 'us-central1'\n",
        "endpoint = aiplatform.Endpoint(endpoint_name=f\"projects/{project_id}/locations/{region}/endpoints/{endpoint_id}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cW7gu2kdyckE",
      "metadata": {
        "executionInfo": {
          "elapsed": 4,
          "status": "ok",
          "timestamp": 1735716932271,
          "user": {
            "displayName": "",
            "userId": ""
          },
          "user_tz": -330
        },
        "id": "cW7gu2kdyckE"
      },
      "outputs": [],
      "source": [
        "def deploy_model_with_dedicated_resources_sample(\n",
        "    project,\n",
        "    location,\n",
        "    model_name: str,\n",
        "    machine_type: str,\n",
        "    endpoint: Optional[aiplatform.Endpoint] = None,\n",
        "    deployed_model_display_name: Optional[str] = None,\n",
        "    traffic_percentage: Optional[int] = 0,\n",
        "    traffic_split: Optional[Dict[str, int]] = None,\n",
        "    min_replica_count: int = 1,\n",
        "    max_replica_count: int = 1,\n",
        "    accelerator_type: Optional[str] = None,\n",
        "    accelerator_count: Optional[int] = None,\n",
        "    # explanation_metadata: Optional[explain.ExplanationMetadata] = None,\n",
        "    # explanation_parameters: Optional[explain.ExplanationParameters] = None,\n",
        "    # metadata: Optional[Sequence[Tuple[str, str]]] = (),\n",
        "    sync: bool = True,\n",
        "):\n",
        "    \"\"\"\n",
        "    model_name: A fully-qualified model resource name or model ID.\n",
        "          Example: \"projects/123/locations/us-central1/models/456\" or\n",
        "          \"456\" when project and location are initialized or passed.\n",
        "    \"\"\"\n",
        "\n",
        "    aiplatform.init(project=project, location=location)\n",
        "\n",
        "    model = aiplatform.Model(model_name=model_name)\n",
        "\n",
        "    # The explanation_metadata and explanation_parameters should only be\n",
        "    # provided for a custom trained model and not an AutoML model.\n",
        "    model.deploy(\n",
        "        endpoint=endpoint,\n",
        "        deployed_model_display_name=deployed_model_display_name,\n",
        "        traffic_percentage=traffic_percentage,\n",
        "        traffic_split=traffic_split,\n",
        "        machine_type=machine_type,\n",
        "        min_replica_count=min_replica_count,\n",
        "        max_replica_count=max_replica_count,\n",
        "        accelerator_type=accelerator_type,\n",
        "        accelerator_count=accelerator_count,\n",
        "        # explanation_metadata=explanation_metadata,\n",
        "        # explanation_parameters=explanation_parameters,\n",
        "        # metadata=metadata,\n",
        "        sync=sync,\n",
        "    )\n",
        "\n",
        "    model.wait()\n",
        "\n",
        "    print(model.display_name)\n",
        "    print(model.resource_name)\n",
        "    return model\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9CclWwvOyckF",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "executionInfo": {
          "elapsed": 16978,
          "status": "ok",
          "timestamp": 1735717438703,
          "user": {
            "displayName": "",
            "userId": ""
          },
          "user_tz": -330
        },
        "id": "9CclWwvOyckF",
        "outputId": "af4fcb5c-f78b-4aa9-8bcc-a16c5e4bb939"
      },
      "outputs": [],
      "source": [
        "output = deploy_model_with_dedicated_resources_sample(project='<GCP Project Name>', location='us-central1', model_name= '<Model-Name>', machine_type= 'n2-standard-80', endpoint=endpoint)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "name": "Vertex AI Model Deployment",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.10"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
